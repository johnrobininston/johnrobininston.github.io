{
  "hash": "70d3d83948f0d2e1335b9ce052cd45dd",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Fundamentals of Probability Theory\nauthor: John Robin Inston\ndate: \"2025-06-01\"\ndate-modified: \"2025-07-23\"\ncategories: [Data Science with R, Probability Theory]\ntoc: true\ntitle-block-banner: true\n---\n\nThis post contains notes for Chapter 5 of my course series [Data Science with R](/courses/intro_to_data_science/index.qmd) covering some fundamentals of probability theory.  The material in this note is focussed on developing intuitive understanding for those who perhaps do not have a formal mathematical background.  For a more rigorous measure theoretic definitions see my notes on Probability Theory.\n\n## Probability\n\nLet us begin like all good courses on the fundamentals of probability by considering the simple experiment of flipping a fair coin.  This is a **random experiment** with **finite** and **discrete** outcomes, i.e. the results of the experiment can be either heads or tails and do not know which in advance.  \n\nA collection of possible outcomes is known as an **event**, for example we define the event of the coin landing on heads by $H$.\n\nThe **probability** of a discrete event $H$ occuring is given by:\n\n$$\n\\mathbb{P}(A) := \\frac{\\text{number of ways for }H\\text{ to occur}}{\\text{total number of possible outcomes}}\n$$\n\nFor our coin flipping example we have 2 possible outcomes and thus\n\n$$\n\\mathbb{P}(H)=\\mathbb{P}(T)=\\frac{1}{2}.\n$$\n\n:::{.callout-note icon=false}\n\n## Definition: Sample Space\n\nThe **sample space** for a random experiment, denoted by the capital Greek letter Omega $\\Omega$, is the set of all possible outcomes of the experiment.  \n\n:::\n\nA sample space is said to be **discrete** if it has finite (or more specifically countable) possible outcomes (e.g. coin flips, dice rolls).  Otherwise, the sample space is said to be **continuous** (e.g. height of individuals measured, speed of birds).\n\nSince the sample space contains all outcomes and it is certain that something will happen we have that $\\mathbb{P}(\\Omega)=1$.  Equivalently, the probability of nothing happening, denoted by the empty set $\\emptyset$, is $\\mathbb{P}(\\emptyset)=0$.  Finally, intuitively the probability of any event can never be negative, and can never be greater than 1, or written mathematically\n\n$$\n\\forall A,~0\\leq \\mathbb{P}(A)\\leq 1.\n$$\n\nThese fundamental properties are known as the **probability axioms**.\n\n### Probability Zero Events\n\nWe note that when we are considering random experiments with continuous sample spaces, a **probability zero event** is not the same as that event being **impossible**.  This might seem like a crazy thing to say but lets develop our intuition with an example. \n\nConsider the continuous interval $[0,1]$.  Let us say that we have equal probability of choosing any real number (decimal of up to infinite length) in this interval.  *What is the probability that we select exactly $0.5$?*\n\nYou would correctly say 0, we have uncountably infinite events and only one that we care about, hence this is a zero probability event.\n\nHowever, you could have chosen 0.5.  In fact, you are certain to choose some number and whatever number you choose also was a probability zero event!  \n\n### Venn Diagrams\n\nTo visualize the probability of random experiments, and to gain an intuitive understanding of the underlying set theory notation, we can use Venn diagrams. \n\nTo consider a new and more interesting example, we turn to a fair 10-sided dice.  The sample space is\n\n$$\n\\Omega := \\{1,2,3,4,5,6,7,8,9,10\\}.\n$$\n\nWe then define the events:\n\n1. $A$ - roll a number less than 5; and\n2. $B$ - roll a number greater than 3,\n\nwith probabilities\n\n$$\n\\mathbb{P}(A)=\\frac{4}{10}=\\frac{2}{5}\\quad \\& \\quad \\mathbb{P}(B)=\\frac{7}{10}.\n$$\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Venn Diagram of Set A and B](index_files/figure-html/venn-plot-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## Probability Laws\n\n### Mutual Exclusivity\n\nConsider two general events $A$ and $B$.  We say that the events are **mutually exclusive** if they cannot happen at the same time, or written mathematically\n$$\n\\mathbb{P}(A\\cap B) = 0.\n$$\n\n![Venn diagram of mutually exclusive events.](exclusive.png)\n\nThus, if two events are not mutually exclusive, they overlap when drawn as a Venn diagram.\n\n![Venn diagram of mutually inclusive events.](not_exclusive.png)\n\n### Addition Rule\n\nThe **addition rule** states that \n$$\n\\mathbb{P}(A\\cup B)=\\mathbb{P}(A) + \\mathbb{P}(B) -\\mathbb{P}(A\\cap B),\n$$\n\ni.e. the probabiity that event $A$ or $B$ occurs is equal to the sum of the probabilities that events $A$ and $B$ occur minus the probability that both events $A$ and $B$ occur.\n\n### Complementary Events\n\nThe **complement** $A^c$ of an event $A$ means all outcomes besides those contained in $A$.\n\n![Venn diagram of event complement.](complement.png)\n\nThus we have the helpful result\n$$\n\\mathbb{P}(A^c)= 1-\\mathbb{P}(A).\n$$\n\n### Conditional Events\n\nSometimes it is easier to think about the probability of an event $A$ conditional on some other event $B$.  Formally written, the **conditional probability** of $A$ occurring given that event $B$ has occurred is \n$$\n\\mathbb{P}(A|B) = \\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)}.\n$$\n\n### Independent Events\n\nTwo events $A$ and $B$ are said to be **independent** if\n$$\n\\mathbb{P}(A|B)=\\mathbb{P}(A).\n$$\n\nNote that this also allows us to obtain the equivalent definition using the definition of conditional probability:\n$$\n\\mathbb{P}(A|B)=\\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)}=\\mathbb{P}(A)\\implies\\mathbb{P}(A\\cap B)=\\mathbb{P}(A)\\times\\mathbb{P}(B).\n$$\n\n### Bayes Theorem\n\nThe fundamental result of Bayesian statistics is **Bayes theorem** which states that\n$$\n\\mathbb{P}(A|B)=\\frac{\\mathbb{P}(B|A)\\mathbb{P}(A)}{\\mathbb{P}(B)}.\n$$\n\n## Random Variables\n\nIntuitively, a **random variable** $X$ is a function that takes values in a support (some prespecified range of values) with some given probability.  We often denote random variables with capital letter $X$, $Y$ or $Z$.\n\nIf the support of a random variable is **countable** then the random variable is said to be **discrete**, otherwise it is said to be **continuous**.  \n\n### Discrete Random Variables\n\nConsider a discrete random variable $X$ that has countable support.  We define the **probability mass function (PMF)** $p_X(x)$ of the random variable by\n$$\np_X(x)=\\mathbb{P}(X=x),\n$$\n\ni.e. the probability mass function gives the probabilities of the random variable taking certain values in its support.  From the  PMF we can define the **cumulative distribution function** as\n$$\nF_X(x)=\\mathbb{P}(X\\leq x).\n$$\n\nFor example, let $X$ be a random variable describing a fair 6-sided dice.  Thus $X$ has support $\\{1,2,3,4,5,6\\}$ and its PMF can be summarised as\n$$\n\\mathbb{P}(X=x)=\\frac{1}{6}~~\\forall x\\in\\{1,2,3,4,5,6\\}.\n$$\n\nWe say that $X$ follows a **discrete uniform distribution** and this is one example of a discrete distribution family.  The common discrete distributions we will explore include:\n\n1. Bernoulli Distribution;\n2. Binomial Distribution;\n3. Discrete Uniform Distribution;\n4. Poisson Distribution.\n\n#### Discrete Expectation\n\nThe expectation of a random variable gives the average of all values generated by the random variable under repeated sampling.  For a discrete random variable this is given by the weighted sum\n$$\n\\mathbb{E}[X] = \\sum_{x}x\\cdot\\mathbb{P}(X=x).\n$$\n\nReturning to our example, we can compute the expectation of the discrete unform random variable as\n$$\n\\begin{align}\n\\mathbb{E}[X] & = \\sum_{x=1}^6 x\\cdot\\mathbb{P}(X=x) \\\\\n& = \\frac{1}{6}\\cdot (1+2+3+4+5+6) = 21/6 = 3.5.\n\\end{align}\n$$\n\n### Continuous Random Variables\n\nNow consider a continuous random variable $X$ taking values in some continuous support.  Notice now that it would be non-sensical to try to define a mass function as above since $\\mathbb{P}(X=x)=0$ for all $x$.  We instead must define a function\n$f_X(x)$ known as the probability density function which gives the density of $X$ across its support.\n\nTo improve our intuition about what a density function is, let us find the density function for a continuous random variable using probability laws.  Let $X$ be continuous and take values in the interval $[0,10]$ with **equal probability**.  The density must be the same across all values of $x$ and so we need can state that for some constant $c$\n$$\nf(x)=c;~~\\forall x.\n$$\n\nFurther the *\"sum\"* of the probabilities of all values must equal 1.  Since we are *\"summing\"* over a continuous interval we instead use integration, i.e. we have that\n$$\n\\int_0^{10}f_X(x)dx = \\int_0^{10}cdx =  1.\n$$\n\nSome simple calculus gives us that\n$$\n[cx]_{x=0}^{10}=10c=1\\implies c=\\frac{1}{10}.\n$$\n\nThus the density can be summarized as\n$$\nf_X(x) = \\frac{1}{10};~~\\forall x\\in [0,10].\n$$\n\nThis is an example of a **continuous uniform distribution**.  The standard continuous probability distributions we shall be considering include:\n\n1. Continuous Uniform Distribution;\n2. Exponential Distribution;\n3. Normal Distribution.\n\nThe **cumulative distribution function** is defined as\n$$\nF_X(x) := \\mathbb{P}(X\\leq x) =  \\int_{0}^x f_X(x)dx.\n$$\n\nThus, in the continuous setting we can only compute the probability of **intervals of the support**. \n\n#### Continuous Expectation\n\nSimilarly, the continuous expectation is intuitively just the infinite weighted sum (i.e. an integral) defined as\n$$\n\\mathbb{E}[X] := = \\int_X x dF(x) = \\int_X x\\cdot f_X(x) dx.\n$$\n\nFor our example we can compute the expectation as\n$$\n\\mathbb{E}[X] = \\int_{0}^{10} x\\cdot \\frac{1}{10} dx = \\left[\\frac{x^2}{20}\\right]_{x=0}^{10} = \\frac{100}{20} = 5.\n$$\n\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}